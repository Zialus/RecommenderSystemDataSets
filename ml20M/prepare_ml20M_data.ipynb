{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified ml-20m.zip\n"
     ]
    }
   ],
   "source": [
    "# Download the data.\n",
    "url = 'http://files.grouplens.org/datasets/movielens/'\n",
    "\n",
    "\n",
    "def maybe_download(filename, expected_bytes):\n",
    "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        filename, _ = urllib.request.urlretrieve(url + filename, filename)\n",
    "    statinfo = os.stat(filename)\n",
    "    if statinfo.st_size == expected_bytes:\n",
    "        print('Found and verified', filename)\n",
    "    else:\n",
    "        print(statinfo.st_size)\n",
    "        raise Exception('Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "    return filename\n",
    "\n",
    "\n",
    "data_file = maybe_download('ml-20m.zip', 198702078)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-20m.zip\n",
      "  inflating: ml-20m/genome-scores.csv  \n",
      "  inflating: ml-20m/genome-tags.csv  \n",
      "  inflating: ml-20m/links.csv        \n",
      "  inflating: ml-20m/movies.csv       \n",
      "  inflating: ml-20m/ratings.csv      \n",
      "  inflating: ml-20m/README.txt       \n",
      "  inflating: ml-20m/tags.csv         \n"
     ]
    }
   ],
   "source": [
    "get_ipython().system(u'unzip -o ml-20m.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file should look like\n",
    "'''\n",
    "userId,movieId,rating,timestamp\n",
    "1,2,3.5,1112486027\n",
    "1,29,3.5,1112484676\n",
    "1,32,3.5,1112484819\n",
    "1,47,3.5,1112484727\n",
    "1,50,3.5,1112484580\n",
    "1,112,3.5,1094785740\n",
    "1,151,4.0,1094785734\n",
    "1,223,4.0,1112485573\n",
    "1,253,4.0,1112484940\n",
    "'''\n",
    "m = 138493\n",
    "n = 131262\n",
    "nnz_train = 18000236\n",
    "nnz_test = 2000027\n",
    "\n",
    "user, item, rating = np.loadtxt('ml-20m/ratings.csv', delimiter=',', skiprows=1,\n",
    "                                dtype=[('f0', np.int32), ('f1', np.int32), ('f2', np.float)],\n",
    "                                unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     1      1      1 ... 138493 138493 138493]\n",
      "[    2    29    32 ... 69644 70286 71619]\n",
      "[3.5 3.5 3.5 ... 3.  5.  2.5]\n",
      "\n",
      "1\n",
      "1\n",
      "0.5\n",
      "\n",
      "138493\n",
      "131262\n",
      "5.0\n",
      "\n",
      "138493\n",
      "26744\n",
      "10\n",
      "\n",
      "20000263\n"
     ]
    }
   ],
   "source": [
    "print(user)\n",
    "print(item)\n",
    "print(rating)\n",
    "print(\"\")\n",
    "print(np.min(user))\n",
    "print(np.min(item))\n",
    "print(np.min(rating))\n",
    "print(\"\")\n",
    "print(np.max(user))\n",
    "print(np.max(item))\n",
    "print(np.max(rating))\n",
    "print(\"\")\n",
    "print(np.unique(user).size)\n",
    "print(np.unique(item).size)\n",
    "print(np.unique(rating).size)\n",
    "print(\"\")\n",
    "print(user.size)\n",
    "\n",
    "assert np.max(user) == m\n",
    "assert np.max(item) == n\n",
    "assert user.size == nnz_train + nnz_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = np.vstack((user, item))\n",
    "\n",
    "user_item_train, user_item_test, rating_train, rating_test = train_test_split(user_item.T,\n",
    "                                                                              rating,\n",
    "                                                                              test_size=nnz_test,\n",
    "                                                                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_test_coo = sparse.coo_matrix((rating_test, (user_item_test[:, 0], user_item_test[:, 1])))\n",
    "assert R_test_coo.nnz == nnz_test\n",
    "\n",
    "outfile_test = open(\"test.txt\", 'w')\n",
    "for i in range(nnz_test):\n",
    "    outfile_test.write(str((user_item_test[i, 0])) + \" \" + str((user_item_test[i, 1])) + \" \" + str(rating_test[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test data, we need COO format to calculate test RMSE\n",
    "\n",
    "R_test_coo.data.astype(np.float32).tofile('R_test_coo.data.bin')\n",
    "R_test_coo.row.tofile('R_test_coo.row.bin')\n",
    "R_test_coo.col.tofile('R_test_coo.col.bin')\n",
    "\n",
    "test_data = np.fromfile('R_test_coo.data.bin', dtype=np.float32)\n",
    "test_row = np.fromfile('R_test_coo.row.bin', dtype=np.int32)\n",
    "test_col = np.fromfile('R_test_coo.col.bin', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.5 2.  3.5 ... 2.5 3.5 5. ]\n",
      "[122270  49018  89527 ...  29335 124295  73174]\n",
      "[  8360     32 109374 ...   3616  53125     48]\n",
      "\n",
      "[3.5 2.  3.5 ... 2.5 3.5 5. ]\n",
      "[122270  49018  89527 ...  29335 124295  73174]\n",
      "[  8360     32 109374 ...   3616  53125     48]\n"
     ]
    }
   ],
   "source": [
    "print(R_test_coo.data)\n",
    "print(R_test_coo.row)\n",
    "print(R_test_coo.col)\n",
    "print(\"\")\n",
    "print(test_data)\n",
    "print(test_row)\n",
    "print(test_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "138493\n",
      "131258\n",
      "\n",
      "0.5\n",
      "1\n",
      "1\n",
      "\n",
      "138493\n",
      "135697\n",
      "26744\n",
      "17719\n"
     ]
    }
   ],
   "source": [
    "print(np.max(R_test_coo.data))\n",
    "print(np.max(R_test_coo.row))\n",
    "print(np.max(R_test_coo.col))\n",
    "print(\"\")\n",
    "print(np.min(R_test_coo.data))\n",
    "print(np.min(R_test_coo.row))\n",
    "print(np.min(R_test_coo.col))\n",
    "print(\"\")\n",
    "print(np.unique(user).size)\n",
    "print(np.unique(R_test_coo.row).size)\n",
    "print(np.unique(item).size)\n",
    "print(np.unique(R_test_coo.col).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train_coo = sparse.coo_matrix((rating_train, (user_item_train[:, 0], user_item_train[:, 1])))\n",
    "assert R_train_coo.nnz == nnz_train\n",
    "\n",
    "outfile_train = open(\"train.txt\", 'w')\n",
    "for i in range(nnz_train):\n",
    "    outfile_train.write(str((user_item_train[i, 0])) + \" \" + str((user_item_train[i, 1])) + \" \" + str(rating_train[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for training data, we need COO format to calculate training RMSE\n",
    "# we need CSR format R when calculate X from \\Theta\n",
    "# we need CSC format of R when calculating \\Theta from X\n",
    "R_train_coo.data.astype(np.float32).tofile('R_train_coo.data.bin')\n",
    "R_train_coo.row.tofile('R_train_coo.row.bin')\n",
    "R_train_coo.col.tofile('R_train_coo.col.bin')\n",
    "\n",
    "train_data = np.fromfile('R_train_coo.data.bin', dtype=np.float32)\n",
    "train_row = np.fromfile('R_train_coo.row.bin', dtype=np.int32)\n",
    "train_col = np.fromfile('R_train_coo.col.bin', dtype=np.int32)\n",
    "\n",
    "R_train_csr = R_train_coo.tocsr()\n",
    "R_train_csc = R_train_coo.tocsc()\n",
    "\n",
    "R_train_csr.data.astype(np.float32).tofile('R_train_csr.data.bin')\n",
    "R_train_csr.indices.tofile('R_train_csr.indices.bin')\n",
    "R_train_csr.indptr.tofile('R_train_csr.indptr.bin')\n",
    "R_train_csc.data.astype(np.float32).tofile('R_train_csc.data.bin')\n",
    "R_train_csc.indices.tofile('R_train_csc.indices.bin')\n",
    "R_train_csc.indptr.tofile('R_train_csc.indptr.bin')\n",
    "\n",
    "train_csc = np.fromfile('R_train_csc.data.bin', dtype=np.float32)\n",
    "train_csr = np.fromfile('R_train_csr.data.bin', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "138493\n",
      "131262\n",
      "\n",
      "0.5\n",
      "1\n",
      "1\n",
      "\n",
      "[2.  3.5 1.5 ... 3.5 5.  3.5]\n",
      "[123514  33255 101944 ...  15191  92011 111373]\n",
      "[3986 6724 5504 ... 2717 1276 2640]\n",
      "\n",
      "[2.  3.5 1.5 ... 3.5 5.  3.5]\n",
      "[123514  33255 101944 ...  15191  92011 111373]\n",
      "[3986 6724 5504 ... 2717 1276 2640]\n",
      "\n",
      "[3.5 3.5 3.5 ... 3.  5.  2.5]\n",
      "[       0        0      158 ... 17999818 17999891 18000236]\n",
      "[    2    47    50 ... 69644 70286 71619]\n",
      "\n",
      "[3.5 3.5 3.5 ... 0.  0.  0. ]\n",
      "\n",
      "[4. 5. 4. ... 4. 3. 4.]\n",
      "[       0        0    44817 ... 18000235 18000235 18000236]\n",
      "[     3      6      8 ...  79570  65409 133047]\n",
      "\n",
      "[4. 5. 4. ... 0. 0. 0.]\n",
      "\n",
      "138493\n",
      "138493\n",
      "26744\n",
      "26325\n"
     ]
    }
   ],
   "source": [
    "print(np.max(R_train_coo.data))\n",
    "print(np.max(R_train_coo.row))\n",
    "print(np.max(R_train_coo.col))\n",
    "print(\"\")\n",
    "print(np.min(R_train_coo.data))\n",
    "print(np.min(R_train_coo.row))\n",
    "print(np.min(R_train_coo.col))\n",
    "print(\"\")\n",
    "print(R_train_coo.data)\n",
    "print(R_train_coo.row)\n",
    "print(R_train_coo.col)\n",
    "print(\"\")\n",
    "print(train_data)\n",
    "print(train_row)\n",
    "print(train_col)\n",
    "print(\"\")\n",
    "print(R_train_csr.data)\n",
    "print(R_train_csr.indptr)\n",
    "print(R_train_csr.indices)\n",
    "print(\"\")\n",
    "print(train_csr)\n",
    "print(\"\")\n",
    "print(R_train_csc.data)\n",
    "print(R_train_csc.indptr)\n",
    "print(R_train_csc.indices)\n",
    "print(\"\")\n",
    "print(train_csc)\n",
    "print(\"\")\n",
    "print(np.unique(user).size)\n",
    "print(np.unique(R_train_coo.row).size)\n",
    "print(np.unique(item).size)\n",
    "print(np.unique(R_train_coo.col).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing extra meta_modified_all file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"writing extra meta_modified_all file\")\n",
    "\n",
    "outfile_meta = open(\"meta_modified_all\", 'w')\n",
    "outfile_meta.write(str(m) + \" \" + str(n) + \"\\n\" + str(nnz_train) + \"\\n\")\n",
    "outfile_meta.write(\"\"\"R_train_coo.data.bin\n",
    "R_train_coo.row.bin\n",
    "R_train_coo.col.bin\n",
    "R_train_csr.indptr.bin\n",
    "R_train_csr.indices.bin\n",
    "R_train_csr.data.bin\n",
    "R_train_csc.indptr.bin\n",
    "R_train_csc.indices.bin\n",
    "R_train_csc.data.bin\n",
    "\"\"\")\n",
    "outfile_meta.write(str(nnz_test) + \" \" + \"test.txt\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing extra meta file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"writing extra meta file\")\n",
    "\n",
    "outfile_meta = open(\"meta\", 'w')\n",
    "outfile_meta.write(str(m) + \" \" + str(n) + \"\\n\" + str(nnz_train) + \"\\n\")\n",
    "outfile_meta.write(str(nnz_train) + \" \" + \"train.txt\\n\")\n",
    "outfile_meta.write(str(nnz_test) + \" \" + \"test.txt\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
